{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/df_noticias_if.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>titulo</th>\n",
       "      <th>conteudo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Campus Barbacena divulga Resultado Provisório ...</td>\n",
       "      <td>\\n\\n\\tO Campus Barbacena divulgou o Resultado ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Divulgado o Edital de convocação de assembleia...</td>\n",
       "      <td>\\n\\n\\tDivulgado o Edital de convocação de asse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Pesquisador da Bélgica realiza palestra no Cam...</td>\n",
       "      <td>\\n\\n\\tO pesquisador da Bélgica, Luc Vankrunkel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Divulgada a homologação das inscrições à candi...</td>\n",
       "      <td>\\n\\n\\tDivulgada a homologação das inscrições à...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Aprovado Regulamento de Eventos, Cerimonial e ...</td>\n",
       "      <td>\\n\\n\\tO Regulamento, aprovado no dia 05 de set...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data                                             titulo  \\\n",
       "0  14/09/2017  Campus Barbacena divulga Resultado Provisório ...   \n",
       "1  14/09/2017  Divulgado o Edital de convocação de assembleia...   \n",
       "2  14/09/2017  Pesquisador da Bélgica realiza palestra no Cam...   \n",
       "3  14/09/2017  Divulgada a homologação das inscrições à candi...   \n",
       "4  14/09/2017  Aprovado Regulamento de Eventos, Cerimonial e ...   \n",
       "\n",
       "                                            conteudo  \n",
       "0  \\n\\n\\tO Campus Barbacena divulgou o Resultado ...  \n",
       "1  \\n\\n\\tDivulgado o Edital de convocação de asse...  \n",
       "2  \\n\\n\\tO pesquisador da Bélgica, Luc Vankrunkel...  \n",
       "3  \\n\\n\\tDivulgada a homologação das inscrições à...  \n",
       "4  \\n\\n\\tO Regulamento, aprovado no dia 05 de set...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data                                               14/09/2017\n",
       "titulo      Campus Barbacena divulga Resultado Provisório ...\n",
       "conteudo    \\n\\n\\tO Campus Barbacena divulgou o Resultado ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\tO pesquisador da Bélgica, Luc Vankrunkelsven, fará uma palestra no dia 27 de setembro, no Auditório I, às 18h30, sobre \"Agroecologia na Bélgia , Zona da Mata-MG e no Brasil: novidades no ar\".\n",
      "\n",
      "\tA atividade é gratuita.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[2]['conteudo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-Processamento \n",
    "\n",
    "Consiste em processar os textos antes de realizar sua conversção para um formato numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo todo o texto para minúsculas e criando nova coluna\n",
    "df['text_lower'] = df['conteudo'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \\n\\n\\to campus barbacena divulgou o resultado ...\n",
       "1    \\n\\n\\tdivulgado o edital de convocação de asse...\n",
       "2    \\n\\n\\to pesquisador da bélgica, luc vankrunkel...\n",
       "3    \\n\\n\\tdivulgada a homologação das inscrições à...\n",
       "4    \\n\\n\\to regulamento, aprovado no dia 05 de set...\n",
       "5    \\n\\n\\tos alunos interessados em imprimir seus ...\n",
       "6    \\n\\n\\tnesta terça-feira,12, aconteceu na diret...\n",
       "7    \\n\\n\\to if sudeste mg, campus barbacena, por m...\n",
       "8    \\n\\n\\ta diretoria de pesquisa, inovação e pós-...\n",
       "9    \\n\\n\\to aluno do curso superior de tecnologia ...\n",
       "Name: text_lower, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_lower'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    O Campus Barbacena divulgou o Resultado Provis...\n",
       "1    Divulgado o Edital de convocação de assembleia...\n",
       "2    O pesquisador da Bélgica, Luc Vankrunkelsven, ...\n",
       "3    Divulgada a homologação das inscrições à candi...\n",
       "4    O Regulamento, aprovado no dia 05 de setembro ...\n",
       "5    Os alunos interessados em imprimir seus certif...\n",
       "6    Nesta terça-feira,12, aconteceu na Diretoria d...\n",
       "7    O IF Sudeste MG, Campus Barbacena, por meio da...\n",
       "8    A Diretoria de Pesquisa, Inovação e Pós-gradua...\n",
       "9    O aluno do curso Superior de Tecnologia em Sis...\n",
       "Name: conteudo, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['conteudo'].apply(lambda x: x.replace('\\n','').replace('\\t', '')).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removendo pontuação\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\tO Campus Barbacena divulgou o Resultado Provisório do VIII Simpósio de Pesquisa e Inovação\\n\\n\\tOs estudantes devem ficar atentos as observações que constam no final do documento\\n\\nLeia o documento\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join([l for l in df.iloc[0]['conteudo'] if l not in punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>titulo</th>\n",
       "      <th>conteudo</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Campus Barbacena divulga Resultado Provisório ...</td>\n",
       "      <td>O Campus Barbacena divulgou o Resultado Provis...</td>\n",
       "      <td>o campus barbacena divulgou o resultado provis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Divulgado o Edital de convocação de assembleia...</td>\n",
       "      <td>Divulgado o Edital de convocação de assembleia...</td>\n",
       "      <td>divulgado o edital de convocação de assembleia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Pesquisador da Bélgica realiza palestra no Cam...</td>\n",
       "      <td>O pesquisador da Bélgica, Luc Vankrunkelsven, ...</td>\n",
       "      <td>o pesquisador da bélgica, luc vankrunkelsven, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Divulgada a homologação das inscrições à candi...</td>\n",
       "      <td>Divulgada a homologação das inscrições à candi...</td>\n",
       "      <td>divulgada a homologação das inscrições à candi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/09/2017</td>\n",
       "      <td>Aprovado Regulamento de Eventos, Cerimonial e ...</td>\n",
       "      <td>O Regulamento, aprovado no dia 05 de setembro ...</td>\n",
       "      <td>o regulamento, aprovado no dia 05 de setembro ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         data                                             titulo  \\\n",
       "0  14/09/2017  Campus Barbacena divulga Resultado Provisório ...   \n",
       "1  14/09/2017  Divulgado o Edital de convocação de assembleia...   \n",
       "2  14/09/2017  Pesquisador da Bélgica realiza palestra no Cam...   \n",
       "3  14/09/2017  Divulgada a homologação das inscrições à candi...   \n",
       "4  14/09/2017  Aprovado Regulamento de Eventos, Cerimonial e ...   \n",
       "\n",
       "                                            conteudo  \\\n",
       "0  O Campus Barbacena divulgou o Resultado Provis...   \n",
       "1  Divulgado o Edital de convocação de assembleia...   \n",
       "2  O pesquisador da Bélgica, Luc Vankrunkelsven, ...   \n",
       "3  Divulgada a homologação das inscrições à candi...   \n",
       "4  O Regulamento, aprovado no dia 05 de setembro ...   \n",
       "\n",
       "                                          text_lower  \n",
       "0  o campus barbacena divulgou o resultado provis...  \n",
       "1  divulgado o edital de convocação de assembleia...  \n",
       "2  o pesquisador da bélgica, luc vankrunkelsven, ...  \n",
       "3  divulgada a homologação das inscrições à candi...  \n",
       "4  o regulamento, aprovado no dia 05 de setembro ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "df['conteudo'] = df['conteudo'].apply(lambda x : re.sub(r'\\n|\\t', '', x))\n",
    "df['text_lower'] = df['text_lower'].apply(lambda x : re.sub(r'\\n|\\t', '', x))\n",
    "df.head()                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'Campus', 'Barbacena', 'divulgou', 'o', 'Resultado', 'Provisório', 'do', 'VIII', 'Simpósio', 'de', 'Pesquisa', 'e', 'Inovação.Os', 'estudantes', 'devem', 'ficar', 'atentos', 'as', 'observações', 'que', 'constam', 'no', 'final', 'do', 'documento.Leia', 'o', 'documento']\n"
     ]
    }
   ],
   "source": [
    "# Tokenização com split\n",
    "\n",
    "print(df.iloc[0]['conteudo'].split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'Campus', 'Barbacena', 'divulgou', 'o', 'Resultado', 'Provisório', 'do', 'VIII', 'Simpósio', 'de', 'Pesquisa', 'e', 'Inovação.Os', 'estudantes', 'devem', 'ficar', 'atentos', 'as', 'observações', 'que', 'constam', 'no', 'final', 'do', 'documento.Leia', 'o', 'documento']\n"
     ]
    }
   ],
   "source": [
    "# Tokenização com nltk\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "print(word_tokenize(df.iloc[0]['conteudo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'O Campus Barbacena divulgou o Resultado Provisorio do VIII Simposio de Pesquisa e Inovacao.Os estudantes devem ficar atentos as observacoes que constam no final do documento.Leia o documento'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remoção de acentos\n",
    "\n",
    "from unicodedata import normalize\n",
    "\n",
    "normalize('NFKD', df.iloc[0]['conteudo']).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "# Removendo stopwords (palavras frequentes mas com pouco significado semântico)\n",
    "\n",
    "import nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['campus', 'barbacena', 'divulgou', 'resultado', 'provisório', 'viii', 'simpósio', 'pesquisa', 'inovação.os', 'estudantes', 'devem', 'ficar', 'atentos', 'observações', 'constam', 'final', 'documento.leia', 'documento']\n"
     ]
    }
   ],
   "source": [
    "print([w for w in word_tokenize(df.iloc[0]['conteudo'].lower()) if (w not in stopwords) and (w not in punctuation)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('program', 'program', 'program')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stemming (Redução do termo a seu radical)\n",
    "\n",
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "\n",
    "stemmer.stem('programar'), stemmer.stem('programava'), stemmer.stem('programaremos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('car', 'box', 'spy', 'child')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatization (EN)\n",
    "# Menos 'agressivo' que o stemming\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lmtzr = WordNetLemmatizer()\n",
    "\n",
    "lmtzr.lemmatize('cars'), lmtzr.lemmatize('boxes'), lmtzr.lemmatize('spies'), lmtzr.lemmatize('children')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jose/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('book', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('on', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('table', 'NN')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parts of Speech Tagging (EN)\n",
    "\n",
    "nltk.pos_tag('the book is on the table'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jose/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'Campus', 'Barbacena', 'divulgou', 'o', 'Resultado', 'Provisório', 'do', 'VIII', 'Simpósio', 'de', 'Pesquisa', 'e', 'Inovação.Os', 'estudantes', 'devem', 'ficar', 'atentos', 'as', 'observações', 'que', 'constam', 'no', 'final', 'do', 'documento.Leia', 'o', 'documento']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(df.iloc[0]['conteudo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unicodedata import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'O Campus Barbacena divulgou o Resultado Provisorio do VIII Simposio de Pesquisa e Inovacao.Os estudantes devem ficar atentos as observacoes que constam no final do documento.Leia o documento'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize('NFKD', df.iloc[0]['conteudo']).encode('ASCII', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jose/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to /home/jose/nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('program', 'program', 'progr')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('programar'), stemmer.stem('programava'), stemmer.stem('prograremos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jose/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('car', 'box', 'spy', 'child')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lemtzr = WordNetLemmatizer()\n",
    "\n",
    "lemtzr.lemmatize('cars'), lemtzr.lemmatize('boxes'), lemtzr.lemmatize('spies'), lemtzr.lemmatize('children')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processa(row):\n",
    "    txt = row['titulo'] + ' ' + row['conteudo']\n",
    "    \n",
    "    return ' '.join([t for t in word_tokenize(txt.lower()) if (t not in stopwords) and (t not in punctuation)])\n",
    "\n",
    "\n",
    "df['doc'] = df.apply(processa, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    campus barbacena divulga resultado provisório ...\n",
       "1    divulgado edital convocação assembleia centro ...\n",
       "2    pesquisador bélgica realiza palestra campus ba...\n",
       "3    divulgada homologação inscrições candidatura c...\n",
       "4    aprovado regulamento eventos cerimonial protoc...\n",
       "Name: doc, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['doc'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização\n",
    "\n",
    "Conversão dos textos para uma representação numérica\n",
    "Forma básica: TF (Term Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x11886 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 67789 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1,1),\n",
    "    max_features=None,\n",
    "    binary=False,\n",
    "    use_idf=True\n",
    ")\n",
    "\n",
    "tfidf_matrix = vectorizer.fit_transform(df['doc'])\n",
    "\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '000', '000957', '001', '002', '002084', '002086', '003', '003360', '008', '009', '00aluno', '00aproveitando', '00dia', '00funcionário', '00lista', '00visitante', '01', '012', '018', '01para', '02', '020', '021', '022', '03', '031', '032', '036', '039', '03dez2015', '04', '05', '050617', '052', '056', '05_final', '05resultado', '06', '06h30', '06resultado', '07', '072016', '076ingrid', '07h', '07h00', '07h30', '07inaptoinparley', '07manhã2º', '07tarde1º', '08', '08h', '08h00min', '08h30', '08h30min', '09', '0909h', '0910h', '0913h', '09h', '09h00min', '09h30', '09h30min', '0foto', '10', '100', '1000', '10024', '100a', '106', '107', '109', '10anexo', '10análise', '10h', '10h00min', '10h30', '10h30m', '10h30min', '10h45mim', '10h45min', '10novo', '10ª', '10º', '11', '110', '115', '116257', '11anexo', '11divulgação', '11h', '11h00', '11h00min', '11h10minhaverá', '11h13', '11h30', '11h30min', '11h30minlocal', '11h40dia', '11ª', '11º', '12', '120', '121', '123ana', '125', '1256', '128', '1283', '129', '12anexo', '12h', '12h00min', '12h30', '12inaptoingreiciane', '13', '136', '13anexo', '13h', '13h00', '13h00mina', '13h10min', '13h30', '13h30min', '13ª', '14', '140', '141', '143', '145', '146', '149', '14h', '14h00min', '14h30', '14hlocal', '14qualidadedevidaedoambiente', '14qualidadedevidaedoambienteos', '15', '150', '15h', '15h30', '15h30min', '15veja', '16', '160', '164', '166', '16h', '16h00min', '16h30', '16h50', '16hcampus', '17', '170', '17data', '17h', '17h00min', '17h30', '17h30local', '17h30min', '17h45', '17ha', '17habertura', '17hdia', '17hleia', '17ª', '18', '180', '1827', '185', '18h', '18h00min', '18h15min', '18h30', '18h30min', '18ha', '18ho', '18htodas', '18ª', '19', '1909', '1910', '1927', '1927an4vppuglifzxylp9u4ogs', '1932', '1945', '1947', '1972', '1979', '1983', '1984', '1986', '1987', '1992', '1993', '1994', '1995', '1999', '19h']\n"
     ]
    }
   ],
   "source": [
    "# Labels das colunas\n",
    "print(vectorizer.get_feature_names()[:200])\n",
    "\n",
    "# Vieram números e partes de links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000957</th>\n",
       "      <th>001</th>\n",
       "      <th>002</th>\n",
       "      <th>002084</th>\n",
       "      <th>002086</th>\n",
       "      <th>003</th>\n",
       "      <th>003360</th>\n",
       "      <th>008</th>\n",
       "      <th>...</th>\n",
       "      <th>último</th>\n",
       "      <th>últimos</th>\n",
       "      <th>única</th>\n",
       "      <th>únicas</th>\n",
       "      <th>único</th>\n",
       "      <th>únicos</th>\n",
       "      <th>úteis</th>\n",
       "      <th>útero</th>\n",
       "      <th>útil</th>\n",
       "      <th>útimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.206311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 11886 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000957  001  002  002084  002086  003  003360  008  ...  último  \\\n",
       "0  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     0.0   \n",
       "1  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     0.0   \n",
       "2  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     0.0   \n",
       "3  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     0.0   \n",
       "4  0.0  0.0     0.0  0.0  0.0     0.0     0.0  0.0     0.0  0.0  ...     0.0   \n",
       "\n",
       "   últimos     única  únicas  único  únicos  úteis  útero  útil  útimo  \n",
       "0      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "1      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "2      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "3      0.0  0.206311     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "4      0.0  0.000000     0.0    0.0     0.0    0.0    0.0   0.0    0.0  \n",
       "\n",
       "[5 rows x 11886 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualização da matriz na forma densa (DataFrame)\n",
    "\n",
    "pd.DataFrame(tfidf_matrix.todense(), columns=vectorizer.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similaridade textual\n",
    "\n",
    "Utiliza o espaço vetorial para calcular a disntância entre cada texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calcula todas as similaridades de cada linha\n",
    "sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04909892938637625"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similaridade entre o primeiro e o segundo texto\n",
    "sim[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similaridade entre o primeiro e o segundo texto\n",
    "sim[0][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'campus barbacena divulga resultado provisório viii simpósio pesquisa inovação campus barbacena divulgou resultado provisório viii simpósio pesquisa inovação.os estudantes devem ficar atentos observações constam final documento.leia documento'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'divulgado edital convocação assembleia centro acadêmico nutrição divulgado edital convocação assembleia centro acadêmico nutrição.leia documento'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'centro memória diaulas abreu reaberto dia 07 agosto centro memória diaulas abreu reaberto visitação novo horário funcionamento 08h 12h 13h 17h agendamentos visitas podem ser realizados contato 32 9 84868411 32 9 82247002 .foto rachel santos'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[100].doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similaridade via distância de Levenshtein\n",
    "from Levenshtein import distance\n",
    "\n",
    "distance(\n",
    "    df.iloc[0].doc,\n",
    "    df.iloc[1].doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance(\n",
    "    df.iloc[0].doc,\n",
    "    df.iloc[100].doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de sentimentos\n",
    "\n",
    "Detectar automaticamente a polaridade e intensidade do sentimento expresso em um texto.\n",
    "\n",
    "\n",
    "## LeIA (Léxico para Inferência Adaptada)\n",
    "LeIA (Léxico para Inferência Adaptada) é um fork do léxico e ferramenta para análise de sentimentos VADER (Valence Aware Dictionary and sEntiment Reasoner) adaptado para textos em português, com suporte para emojis e foco na análise de sentimentos de textos expressos em mídias sociais - mas funcional para textos de outros domínios.\n",
    "\n",
    "A biblioteca preserva a API do VADER, e o texto de entrada não precisa ser pré-processado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from leia import SentimentIntensityAnalyzer\n",
    "\n",
    "s = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.423, 'pos': 0.577, 'compound': 0.6249}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análise de texto simples\n",
    "\n",
    "s.polarity_scores('Eu estou muuuuuuuuuito feliz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.297, 'pos': 0.703, 'compound': 0.7964}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análise de texto com emoji\n",
    "\n",
    "s.polarity_scores('Eu estou muuuuuuuuuito feliz :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.386, 'neu': 0.351, 'pos': 0.263, 'compound': -0.1779}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análise de texto com negação\n",
    "\n",
    "s.polarity_scores('Eu não estou legal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A saída da análise de sentimentos é um dicionário com os seguintes campos:\n",
    "\n",
    "- <code>pos</code>: porcentagem positiva do texto\n",
    "- <code>neg</code>: porcentagem negativa do texto\n",
    "- <code>neu</code>: porcentagem neutra do texto\n",
    "- <code>compound</code>: valor de sentimento geral normalizado, variando de -1 (extremamente negativo) a +1 (extremamente positivo)\n",
    "\n",
    "O valor <code>compound</code> pode ser utilizado para descrever o sentimento predominante no texto, por meio dos limites de valores:\n",
    "\n",
    "- Sentimento positivo: <code>compound >= 0.05</code>\n",
    "- Sentimento negativo: <code>compound <= -0.05</code>\n",
    "- Sentimento neutro: <code>(compound > -0.05) and (compound < 0.05)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
